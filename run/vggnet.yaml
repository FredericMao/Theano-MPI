# VGGNet model and training hyperparameters

source: Theano-MPI # def: Theano-MPI,  Theano-MPI or lasagne

# Learning Parameters
n_epochs: 44 # def: 74 for  VGGNet
learning_rate: 0.002  # def: 0.01 for AlexNet, GoogLeNet and VGGNet
lr_policy: step
lr_step: [20, 40, 60] # def: 20, 40, 60

# Weight Decay
weight_decay: 0.0005 # def: 0.0005 for VGGNet

# Momentum
momentum: 0.9 # def: 0.9

# Model info
name: vggnet
input_width: 224 # def: 227 for AlexNet, 224 for GoogLeNet 
input_height: 224 # def: 227 for AlexNet, 224 for GoogLeNet 

n_softmax_out: 1000

batch_size: 16 # def: 256 for VGGNet, 32 used by caffe

image_mean: RGB_mean


data: imagenet
# Directories
dir_head : /scratch/ilsvrc12/#/work/mahe6562/prepdata_1000cat_128b/   # base dir where hkl training data is kept
label_folder : /labels/  # 
mean_file : /misc/img_mean.npy
train_folder: /train_hkl_b256_b_128/   #/hkl_data/  
val_folder: /val_hkl_b256_b_128/ 
  
# Data
file_batch_size: 128 # def: choose according to the preprocessed hkl file size
